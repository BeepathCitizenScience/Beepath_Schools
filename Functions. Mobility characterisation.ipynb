{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "considerable-model",
   "metadata": {},
   "source": [
    "### Here we define the calculations we'll use in order to characterise the mobility of the participants, in particular we focus on velocities. First we compute the time difference between Geo-locations in seconds. Then we obtain the distance in metres between Geo-locations and the instantaneous velocity, defined as the distance over time difference. Finally, we show how to obtain the Mean Squared Displacement for two cases and the Autocorrelation (of the logarithm of the velocities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-chrome",
   "metadata": {},
   "source": [
    "# INDEX\n",
    "\n",
    "    1. Time difference between Geo-locations in seconds\n",
    "    \n",
    "    2. Euclidean distance between Geo-locations in metres\n",
    "        2.1- Harversine Equation\n",
    "        2.2- UTM projection. Euclidean distance\n",
    "        \n",
    "    3. Instantaneous velocity\n",
    "        \n",
    "    4. Mean Squared Displacement MSD(T)\n",
    "        4.1- Heterogenous case (origin at t=0)\n",
    "        4.2- Homogenous case (averaging over all origins, thermalising)\n",
    "    \n",
    "    5. Auto-correlation function\n",
    "    \n",
    "    6. Tortuosity and Reorientation\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-minnesota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "#%matplotlib inline\n",
    "ox.config(log_console=True)\n",
    "ox.__version__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-freeware",
   "metadata": {},
   "source": [
    "# 1. Time difference between Geo-locations in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functional-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeDifference(df,name_column_time):\n",
    "    \"\"\" Given the dataframe and the name of the column that contains the time of each Geo-location, it returns the dataframe\n",
    "        with a new column corresponding to the time difference between geolocations (so the last element is null)\n",
    "        \n",
    "        Inputs:\n",
    "            - Dataframe\n",
    "            - name of the time column (string). Eg: 'time'\n",
    "        \n",
    "        Outputs:\n",
    "            - Dataframe with a new column corresponding to the time difference between consecutive geolocations\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    df[name_column_time] = pd.to_datetime(df[name_column_time], format='%Y-%m-%d %H:%M:%S')  # Time column to datetime format\n",
    "    df=df.drop_duplicates(subset=[name_column_time],keep='first')  # drop duplicates (impossible)\n",
    "    \n",
    "    # Compute the time difference between consecutive geolocations [in advance: At(i)=t(i+1)-t(i)]\n",
    "    time=df[name_column_time].tolist()   \n",
    "    diff_time=[]\n",
    "    for i in range(1,len(df[name_column_time])):\n",
    "        diff=temps[i]-temps[i-1]\n",
    "        diff_time.append(diff)\n",
    "\n",
    "    diff_time.insert(len(diff_time), np.nan)   # Add NaN value at the end of the list to add as a column in the dataframe\n",
    "                                               # (since we have N data and N-1 time differences)\n",
    " \n",
    "    df['At']=diff_time     # Add new column At corresponding to the time difference in seconds\n",
    "    df['At']=df['At'].dt.seconds\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-tradition",
   "metadata": {},
   "source": [
    "# 2. Euclidian distance between Geo-locations in metres\n",
    "\n",
    "In this work we'll use the Way 1, using the Harvensine Equation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-leave",
   "metadata": {},
   "source": [
    "## 2.1- Harvensine Equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "published-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistanceFromLatLonInM(lat1,lon1,lat2,lon2):\n",
    "    \"\"\" Function that returns the distance in metres between 2 GPS locations in degrees (latitude and longitude).\n",
    "    It is based in the Haversine formula (https://en.wikipedia.org/wiki/Haversine_formula) which takes into account the\n",
    "    Earth's curvature. \n",
    "    \n",
    "    Input:\n",
    "        - 2 GPS coordinates: (latitude1,longitude1) of the first point and (latitude2,longitude2) of the second point. \n",
    "        \n",
    "    Output:\n",
    "        - Distance in metres between the two GPS locations.\n",
    "    \"\"\"\n",
    "    \n",
    "    R = 6371 # Radius of the earth in km\n",
    "    dLat = radians(lat2-lat1)\n",
    "    dLon = radians(lon2-lon1)\n",
    "    rLat1 = radians(lat1)\n",
    "    rLat2 = radians(lat2)\n",
    "    a = sin(dLat/2) * sin(dLat/2) + cos(rLat1) * cos(rLat2) * sin(dLon/2) * sin(dLon/2) \n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = R * c # Distance in km\n",
    "    e= d*1000 #distance in m\n",
    "    \n",
    "    return e\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-profession",
   "metadata": {},
   "source": [
    "## 2.2- UTM projection. Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "variable-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm\n",
    "\n",
    "def GPScoordinates_to_utm(lat,lon):\n",
    "    \"\"\"\" Function that projects the GPS coordinates in degrees (latitude, longitude) into the UTM coordinate system\n",
    "    in order to work with the concept of \"point\" and \"Euclidean distance\" in a plane.\n",
    "    (https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system)\n",
    "    \n",
    "    Note: We are dealing with locations in the same area/region. Otherwise, we should be careful if two locations \n",
    "    belong to different UTM zones when calculating distances, etc. \n",
    "    \n",
    "    Input:\n",
    "        - lists of GPS coordinates: latitude and longitude\n",
    "        \n",
    "    Output:\n",
    "        - lists of the UTM projections of the GPS coordinates: \n",
    "        - The utm package returns Easting, Northing, Zone_number and Zone_letter. So we only store the two first elements\n",
    "    \"\"\"\n",
    "    \n",
    "    lat_utm=[]\n",
    "    lon_utm=[]\n",
    "    for i in range(len(lat)):\n",
    "        u=utm.from_latlon(lat[i],lon[i])  # get the UTM projection\n",
    "        lat_utm.append(u[0])   # Store the projection of latitude and longitude in lists\n",
    "        lon_utm.append(u[1])\n",
    "        \n",
    "    return lat_utm, lon_utm\n",
    "\n",
    "\n",
    "\n",
    "def EuclidianDistance(x1,y1,x2,y2):\n",
    "    \"\"\" Function that returns the distance in metres between 2 points in a plane (NO GPS locs.) \n",
    "    \n",
    "    Note: Be careful as the GPS coordinates (lat,lon) cannot be used, but their projections to a plane (e.g. utm projection).\n",
    "\n",
    "    \n",
    "    Input:\n",
    "        - The coordinates of two points in a plane: (x1,y1) and (x2,y2).\n",
    "        \n",
    "    Output:\n",
    "        - Euclidian distance in metres between the two points.\n",
    "    \"\"\"\n",
    "    \n",
    "    Euclidian_distance = ( (x2-x1)**2 + (y2-y1)**2 ) ** 0.5\n",
    "        \n",
    "    return Euclidian_distance\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-holocaust",
   "metadata": {},
   "source": [
    "# 3. Instantaneous velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantaneous_velocity(distance,time):\n",
    "    \"\"\"\" Function that computes the instantenous velocity between two points, given their distance and their time difference.\n",
    "    \n",
    "    Input:\n",
    "        - Distance between two points or two locations\n",
    "        - Time difference between the two points/locations\n",
    "        \n",
    "    Output:\n",
    "        - Instantenous velocity between the two points\n",
    "    \"\"\"\n",
    "    \n",
    "    v=distance/time\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-disposal",
   "metadata": {},
   "source": [
    "# 4. Mean Squared Displacement\n",
    "\n",
    "$\\Large MSD(T)=\\langle |\\vec{r}(t+T)-\\vec{r}(t)|^2 \\rangle $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-walnut",
   "metadata": {},
   "source": [
    "## 4.1- Heterogeneous case (origin at t=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Obtain the Mean Squared Displacement, averaged over all users (for each time \"s\", averaging over users) and taking\n",
    "    t=0 as the origin (heterogeneous case). \n",
    "    \n",
    "    Inputs:\n",
    "        - Dataframe\n",
    "        \n",
    "    Outputs:\n",
    "        - text files with the MSD(T) for each T and confident intervals of 95%. And the plot of MSD(T).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(\"*.csv\")) #make list of paths for all the csv files (each user)\n",
    "\n",
    "diff_mean_n_square=[]\n",
    "interv_conf_95_plus=[]\n",
    "interv_conf_95_minus=[]\n",
    "\n",
    "for s in range(600):   #loop for each time T (T=1,2,3,...,600)\n",
    "\n",
    "    diff_list2 = [] \n",
    "\n",
    "    for file in all_files:   #loop for each user file (csv). \n",
    "        df = pd.read_csv(file) #read the file\n",
    "\n",
    "        latitude = df['latitude'].tolist()   #latitude and longitude to lists\n",
    "        longitude = df['longitude'].tolist()\n",
    "\n",
    "        if len(latitude) > s:  #use only those files of lenght > s to compute the MSD (because every user has different lenght)\n",
    "\n",
    "            x=latitude[0]\n",
    "            y=longitude[0]\n",
    "            z=latitude[s]\n",
    "            t=longitude[s]                          #|r(s)-r(0)|^2\n",
    "            diff=getDistanceFromLatLonInM(x,y,z,t)  #computes the distances between the origin (t=0) and the position at \"s\"\n",
    "            diff_list2.append(abs(diff)**2)    #append in a list all the distances (squared) # |r(s)-r(0)|^2 for each user\n",
    "\n",
    "\n",
    "    average_diff2=sum(diff_list2)/len(diff_list2)  # <|r(s)-r(0)|^2> average over users for a given s\n",
    "    diff_mean_n_square.append(average_diff2)  #we store the averaged result over users for a every s\n",
    "\n",
    "    mean = average_diff2   #mean, variance and standard deviation for the interval confidence\n",
    "    variance = sum([((xx - mean) ** 2) for xx in diff_list2]) / len(diff_list2)\n",
    "    stddev = variance ** 0.5\n",
    "    interv_conf_95_plus.append(mean+((1.960*stddev)/((len(diff_list2))**0.5)))   #interval confidence of 95% (z=1.960)\n",
    "    interv_conf_95_minus.append(mean-((1.960*stddev)/((len(diff_list2))**0.5)))\n",
    "\n",
    "\n",
    "list_s=[]\n",
    "for i in range(600):\n",
    "    list_s.append(i)\n",
    "\n",
    "#PLOT THE RESULT FOR THE MSD   \n",
    "fig, ax1 = pp.subplots(figsize=(7,5))   \n",
    "ax1.plot(list_s, diff_mean_n_square, '+', label='ordered') \n",
    "ax1.fill_between(list_s, interv_conf_95_minus, interv_conf_95_plus, color='b', alpha=.1)\n",
    "ax1.set_ylabel(r'MSD ($m^2$)',fontsize=14)\n",
    "ax1.set_xlabel(r'T (s)',fontsize=14)\n",
    "ax1.set_yscale('log',basey=10) \n",
    "ax1.set_xscale('log',basex=10) \n",
    "axins2 = inset_axes(ax1, width=\"80%\", height=\"100%\", loc=1,bbox_to_anchor=(0.10,1-0.45,.35,.35), bbox_transform=ax1.transAxes)\n",
    "axins2.plot(list_s, diff_mean_n_square,'+')\n",
    "axins2.fill_between(list_s, interv_conf_95_minus, interv_conf_95_plus, color='b', alpha=.1)\n",
    "\n",
    "\n",
    "# SAVE TO FILES. \n",
    "\n",
    "#np.savetxt('difussion_origin_0.txt', np.array(diff_mean_n_square))\n",
    "#np.savetxt('CI_95_origin_0_plus.txt',np.array(interv_conf_95_plus))\n",
    "#np.savetxt('CI_95_origin_0_minus.txt',np.array(interv_conf_95_minus))\n",
    "\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-lebanon",
   "metadata": {},
   "source": [
    "## 4.2- Homogenous case (averaging over all origins, thermalising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Obtain the Mean Squared Displacement, averaged over all users (for each time \"s\", averaging over users) and also averaging\n",
    "    over all possible origins (thermalising). \n",
    "    \n",
    "    Inputs:\n",
    "        - Dataframe\n",
    "        \n",
    "    Outputs:\n",
    "        - text files with the MSD(T) for each T and confident intervals of 95%. And the plot of MSD(T).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(\"*.csv\")) #make list of paths for all the csv files (each user)\n",
    "\n",
    "diff_mean_s=[]\n",
    "diff_mean_s_square=[]\n",
    "interv_conf_95_plus=[]\n",
    "interv_conf_95_minus=[]\n",
    "\n",
    "for s in range(1,600):   #loop for each T (T=1,2,3,...,200)\n",
    "    diff_mean_n=[]\n",
    "    diff_mean_n_square=[]\n",
    "    \n",
    "    for file in all_files:   #loop for each user file (csv). \n",
    "        df = pd.read_csv(file) #read the file\n",
    "        \n",
    "        latitude = df['latitude'].tolist()   #latitude and longitude to lists\n",
    "        longitude = df['longitude'].tolist()\n",
    "\n",
    "        if len(latitude) > s:   #use only those files of lenght > 200 to compute the MSD (almost all of them)\n",
    "            \n",
    "            diff_list2 = [] \n",
    "            \n",
    "            for x, y, z, t in zip(latitude[0::], longitude[0::], latitude[s::], longitude[s::]): #|r(t+s)-r(t)|^2\n",
    "                diff=getDistanceFromLatLonInM(x,y,z,y)  #computes ALL the distances between locations separated \"s\" timesteps\n",
    "                diff_list2.append(diff**2)    #append in a list all the distances (squared) # |r(t+s)-r(t)|^2\n",
    "                                              #for instance, for s=1:  r1-r0, r2-r1, r3-r2, r4-r1 (all 1 step distances)\n",
    "                                              #for s=2: r2-r0, r3-r1, r4-r2,...etc (for a given individual)\n",
    "      \n",
    "            average_diff2=sum(diff_list2)/len(diff_list2)  # <|r(t+s)-r(t)|^2> average over t (for a given s and a given indiv.)\n",
    "            diff_mean_n_square.append(average_diff2)  #we store the averaged result for each individual in a list (for a given s)\n",
    "    \n",
    "    diff_mean_n_square2=sum(diff_mean_n_square)/len(diff_mean_n_square) #Average over users, for a given s.\n",
    "    diff_mean_s_square.append(diff_mean_n_square2)  #Then for each s, we store the averaged value of users. MSD(s)\n",
    "    mean = diff_mean_n_square2    #mean, variance and st8andard deviation for the interval confidence\n",
    "    variance = sum([((xx - mean) ** 2) for xx in diff_mean_n_square]) / len(diff_mean_n_square)\n",
    "    stddev = variance ** 0.5\n",
    "    interv_conf_95_plus.append(mean+((1.960*stddev)/((len(diff_mean_n_square))**0.5)))   #interval confidence of 95% (z=1.960)\n",
    "    interv_conf_95_minus.append(mean-((1.960*stddev)/((len(diff_mean_n_square))**0.5)))\n",
    "\n",
    "list_s=[]\n",
    "for i in range(1,600):\n",
    "    list_s.append(i)\n",
    "\n",
    "#PLOT THE RESULT FOR THE MSD   \n",
    "fig, ax1 = pp.subplots(figsize=(7,5))   \n",
    "ax1.plot(list_s, diff_mean_s_square, '+', label='ordered') \n",
    "ax1.fill_between(list_s, interv_conf_95_minus, interv_conf_95_plus, color='b', alpha=.1)\n",
    "ax1.set_ylabel(r'MSD ($m^2$)',fontsize=14)\n",
    "ax1.set_xlabel(r'T (s)',fontsize=14)\n",
    "ax1.set_yscale('log',basey=10) \n",
    "ax1.set_xscale('log',basex=10) \n",
    "axins2 = inset_axes(ax1, width=\"80%\", height=\"100%\", loc=1,bbox_to_anchor=(0.10,1-0.45,.35,.35), bbox_transform=ax1.transAxes)\n",
    "axins2.plot(list_s, diff_mean_s_square,'+')\n",
    "\n",
    "#np.savetxt('difussion_homogenous.txt', np.array(diff_mean_s_square))\n",
    "#np.savetxt('ci_95_msd_homogenous_plus.txt', np.array(interv_conf_95_plus))\n",
    "#np.savetxt('ci_95_msd_homogenous_minus.txt', np.array(interv_conf_95_minus))\n",
    "\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-presentation",
   "metadata": {},
   "source": [
    "# 5. Autocorrelation function\n",
    "\n",
    "$\\Large u=\\ln \\left( \\frac{v}{\\langle v \\rangle} \\right)$\n",
    "\n",
    "$\\Large C(\\tau) = \\frac{\\langle \\left[u(t)-\\langle u(t) \\rangle \\right] \\left[ u(t+\\tau)-\\langle u(t) \\rangle \\right] \\rangle}{\\langle \\left[ u(t)-\\langle u(t) \\rangle \\right]^{2} \\rangle }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Obtain the Autocorrelation function C(tau), averaged over all users (for each time \"tau\", averaging over users). Using the \n",
    "    logarithm of the velocity (u=log(u/<v>)) using <v> a scale factor just for units.\n",
    "    \n",
    "    Inputs:\n",
    "        - Dataframe\n",
    "        \n",
    "    Outputs:\n",
    "        - text files with the C(tau) for each tau. And plot of C(tau)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(\"*.csv\")) #make list of paths\n",
    "\n",
    "#SAME CODE BUT NOW FOR S=1,...,600. SAVING THE AUTOCORRELATION VALUES IN A TEXT FILE.\n",
    "corr_mean_s=[]\n",
    "interv_conf_95_plus_log=[]\n",
    "interv_conf_95_minus_log=[]\n",
    "for s in range(1,600):   \n",
    "    corr_mean_n=[]\n",
    "    print(s)\n",
    "    for file in all_files: \n",
    "        df = pd.read_csv(file)      \n",
    "        \n",
    "        v=df['v'][:-1].tolist()   # velocity to list and obtain u=ln(v/<v>) for each user (or the variable we want to study)\n",
    "        mean_v=sum(v)/len(v)\n",
    "        u=[]\n",
    "        for i in range(len(v)):\n",
    "            v_log=np.log(v[i]/mean_v)\n",
    "            u.append(v_log)\n",
    "            \n",
    "        \n",
    "        if len(u) > s:   # Compute autocorrelation and average over all s those users ho has a size >s (obviuosly). \n",
    "            mean=sum(u)/len(u)\n",
    "            variance = sum([((y - mean) ** 2) for y in u]) / len(u)\n",
    "            std= variance ** 0.5  \n",
    "\n",
    "            delta_r_i_rescaled = [(x - mean)/std for x in u]\n",
    "            \n",
    "            res = tuple( i*j for i, j in zip(delta_r_i_rescaled, delta_r_i_rescaled[s:])) \n",
    "            average_corr=sum(res)/len(res)    \n",
    "            corr_mean_n.append(average_corr)\n",
    "            \n",
    "    \n",
    "    corr_mean_n2=sum(corr_mean_n)/len(corr_mean_n)\n",
    "    corr_mean_s.append(corr_mean_n2)\n",
    "    \n",
    "    mean = corr_mean_n2   #mean, variance and standard deviation for the interval confidence\n",
    "    variance = sum([((xx - mean) ** 2) for xx in corr_mean_n]) / len(corr_mean_n)\n",
    "    stddev = variance ** 0.5\n",
    "    interv_conf_95_plus_log.append(mean+((1.960*stddev)/((len(corr_mean_n))**0.5)))   #interval confidence of 95% (z=1.960)\n",
    "    interv_conf_95_minus_log.append(mean-((1.960*stddev)/((len(corr_mean_n))**0.5)))\n",
    "    \n",
    "autocorr=np.array(corr_mean_s)\n",
    "\n",
    "list_s=[]\n",
    "for i in range(1,600):\n",
    "    list_s.append(i)\n",
    "\n",
    "    \n",
    "#PLOT THE RESULT FOR THE C(tau)\n",
    "fig, ax1 = pp.subplots(figsize=(7,5))   \n",
    "ax1.plot(list_s, corr_mean_s, '+') \n",
    "ax1.set_ylabel(r'C($\\tau$)',fontsize=14)\n",
    "ax1.set_xlabel(r'$\\tau$ (s)',fontsize=14)\n",
    "ax1.set_xlim(0,202)\n",
    "axins2 = inset_axes(ax1, width=\"80%\", height=\"100%\", loc=1,bbox_to_anchor=(0.10,1-0.45,.35,.35), bbox_transform=ax1.transAxes)\n",
    "axins2.plot(list_s, corr_mean_s,'+')\n",
    "axins2.set_yscale('log',basey=10) \n",
    "axins2.set_xscale('log',basex=10) \n",
    "\n",
    "\n",
    "\n",
    "#np.savetxt('autocorrelation_log.txt', autocorr)   # save to text\n",
    "#np.savetxt('autocorrelation__CI_plus_log.txt', interv_conf_95_plus_log)\n",
    "#np.savetxt('autocorrelation_CI_minus_log.txt', interv_conf_95_minus_log)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-saver",
   "metadata": {},
   "source": [
    "# 6. Tortuosity and Reorientation\n",
    "\n",
    "\n",
    "\n",
    "$ \\Large T = 1 - <cos(\\theta)>$\n",
    "\n",
    "\n",
    "being $\\theta$ the re-orientation angle between the instantaneous vector of movement connecting the points $i$ and $i+1$ and the vector towards the final destination, connecting the points $i$ and $N$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescribed-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import lpmn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from mpmath import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import lpmn,jv,lpmv\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "\n",
    "\n",
    "def orientation(latitude0,longitude0,latitude1,longitude1):\n",
    "    \"\"\" Given two points that form a vector: origin p0 and destination p1, get their angle (uniquely defined)\n",
    "    \n",
    "    Input:\n",
    "        - origin latitude and longitude (latitude0, longitude0)\n",
    "        - destination latitude and longitude (latitude1, longitude1)\n",
    "    \n",
    "    Output:\n",
    "        - orientation angle between the vector and the x-coordenate (in radians)\n",
    "    \n",
    "    Note: The returned angle is in the range between 0 and 2·pi in counter-clockwise direction\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    p0=(latitude0,longitude0)   #first define the points: p0=(latitude0, longitude0) and p1=(latitude1,longitude1)\n",
    "    p1=(latitude1,longitude1)\n",
    "    p=np.array(p1)-np.array(p0)\n",
    "    \n",
    "    a=np.arctan2(p[1],p[0])         # orientation angle between 0 and 2·pi\n",
    "    if a < 0.0:\n",
    "        b=2*np.pi + a\n",
    "        return b\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def vector(latitude0,longitude0,latitude1,longitude1): \n",
    "    \"\"\" Given two points: origin p0 and destionation p1, get their vector coordenates \n",
    "    \n",
    "    Input:\n",
    "        - origin latitude and longitude (latitude0, longitude0)\n",
    "        - destination latitude and longitude (latitude1, longitude1)\n",
    "        \n",
    "    Output:\n",
    "        - vector coordinates between origin and destination points\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    p0=(latitude0,longitude0)   # first define the points: p0=(latitude0, longitude0) and p1=(latitude1,longitude1)\n",
    "    p1=(latitude1,longitude1)\n",
    "    vec=(p1[0]-p0[0], p1[1]-p0[1]) #vector\n",
    "    return vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def determinant(vec0,vec1):\n",
    "    \"\"\" Given two vectors, compute the determinant. If det<0 means that the second vector has turned in the clockwise direction\n",
    "    \n",
    "    Input:\n",
    "        - two consecutive vectors vec0 and vec1\n",
    "        \n",
    "    Output:\n",
    "        - determinant\n",
    "    \"\"\"\n",
    "    \n",
    "    det=vec0[0]*vec1[1]-vec0[1]*vec1[0]\n",
    "    return det\n",
    "\n",
    "\n",
    "\n",
    "# Obtain the angle between two consecutive vectors (change in orientation, reorientation, turning angle).\n",
    "# This angle is <0 if det<0 (clockwise) and >0 if counter clockwise\n",
    "def reorientation(vec0,vec1):\n",
    "    \"\"\" Given two vectors, obtain the change in the orientation (turning angle) in radians between 0 and 2·pi\n",
    "        We consider a negative angle if the determinant is <0 (clockwise) and positive angle (det>0) if counter-clockwise\n",
    "        \n",
    "    Input:\n",
    "        - two consecutive vectors vec0 and vec1\n",
    "    \n",
    "    Output:\n",
    "        - reorientation angle (turning angle) between vectors in degrees (0 to 2·pi counter-clockwise and 0 to -2·pi clockwise)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    unit_vec0=vec0/np.linalg.norm(vec0)\n",
    "    unit_vec1=vec1/np.linalg.norm(vec1)\n",
    "    dot_product=np.dot(unit_vec0,unit_vec1)\n",
    "    a=np.arccos(dot_product)\n",
    "    det=determinant(vec0,vec1)\n",
    "    if det<0:\n",
    "        return -a\n",
    "    else:\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    \n",
    "def tortuosity(longitudes, latitudes):\n",
    "    \"\"\" Given all the GPS coordenates (latitude and longitude) of the individual trajectory, obtain tortuosity of the path\n",
    "    \n",
    "    Input:\n",
    "        - Lists of latitudes and longitudes of a single path\n",
    "        \n",
    "    Output:\n",
    "        - Single value of the tortuosity of the path\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    latitude=df['latitude'].tolist()    # longitude and latitude to lists\n",
    "    longitude=df['longitude'].tolist()\n",
    "\n",
    "    reorientations=[]   # Re-orientation between the movement vector and the straight vector towards the final point.\n",
    "    for i in range(1,len(latitude)-s):\n",
    "        vectors=vector(latitude[i-1],longitude[i-1],latitude[i+s],longitude[i+s])  #movement vector\n",
    "        vectors_straight=vector(latitude[i-1],longitude[i-1],latitude[-1],longitude[-1])  #straight vector\n",
    "        reorientations.append(np.cos(abs(reorientation(vectors_straight,vectors)))) #reorientation\n",
    "        reorientations2 = [x for x in reorientations if np.isnan(x) == False]  #avoid nan values\n",
    "\n",
    "    efficiency=sum(reorientations2)/len(reorientations2)   # The orientation efficiency is <cos(0)>\n",
    "    tortuosity=1.-efficiency        # The tortuosity is 1 minus the orientation efficiency. \n",
    "\n",
    "    return tortuosity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-client",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
